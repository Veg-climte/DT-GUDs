{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd0ba3-c617-4ddc-8d8e-b5ec2c4a1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Random Forest – zone-wise (biome-wise) relative importance\n",
    "Pipeline:\n",
    "1) Load dependent variable raster (masked to valid range).\n",
    "2) Load biome classification raster and reproject to match the dependent raster.\n",
    "3) Load all explanatory rasters, align to the dependent raster, mask to valid pixels,\n",
    "   and clip each to [1st, 99th] percentile to reduce outliers.\n",
    "4) Train a RandomForestRegressor to compute normalized feature importances:\n",
    "   - overall (all pixels)\n",
    "   - per biome (TBMF, TCF, BF, TGSS, MGS, TUN, MFWS, DXS)\n",
    "5) Save a CSV with overall and biome-wise importances.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -----------------------------\n",
    "# 0) File inputs (placeholders)\n",
    "# -----------------------------\n",
    "dep_file = r\"/path/to/dependent_variable.tif\"          # e.g., threshold map (SPEI-triggered SOS delay)\n",
    "classification_file = r\"/path/to/biome_classification.tif\"\n",
    "\n",
    "# Explanatory variables used (examples across climate, vegetation, soil/structure, and resilience):\n",
    "#   - Aridity Index (AI), VOD-based resilience proxy, Shortwave radiation (Srad), Vapor pressure deficit (VPD),\n",
    "#   - Wind speed (Wind), Annual precipitation (PPT), Vegetation species richness (VegSpecies),\n",
    "#   - NDVI/LAI composite metric (e.g., NDVI_EOS_POS_Difference_LAI), Root/plant hydraulic proxy (rplant),\n",
    "#   - Pre-season drought/temperature indices (e.g., SPEI, STImin), Mean NDVI (mean_NDVI), Soil organic carbon & N (SOC_N)\n",
    "explanatory_files = [\n",
    "    r\"/path/to/AI.tif\",\n",
    "    r\"/path/to/VOD_resilience.tif\",\n",
    "    r\"/path/to/Srad.tif\",\n",
    "    r\"/path/to/VPD.tif\",\n",
    "    r\"/path/to/Wind.tif\",\n",
    "    r\"/path/to/Annual_PPT.tif\",\n",
    "    r\"/path/to/Vegetation_species.tif\",\n",
    "    r\"/path/to/NDVI_EOS_POS_Difference_LAI.tif\",\n",
    "    r\"/path/to/rplant_proxy.tif\",\n",
    "    r\"/path/to/SPEI_STImin.tif\",\n",
    "    r\"/path/to/mean_NDVI.tif\",\n",
    "    r\"/path/to/SOC_N.tif\",\n",
    "]\n",
    "\n",
    "# Biome codes -> labels (example mapping)\n",
    "biome_map = {\n",
    "    4: \"TBMF\", 5: \"TCF\", 6: \"BF\", 8: \"TGSS\",\n",
    "    10: \"MGS\", 11: \"TUN\", 12: \"MFWS\", 13: \"DXS\",\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load dependent variable\n",
    "# -----------------------------\n",
    "dep = rxr.open_rasterio(dep_file).squeeze()\n",
    "\n",
    "# Keep valid range only (example: (-10, 0]; adjust as needed for your study)\n",
    "dep = dep.where((dep > -10) & (dep <= -0.5))\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Load & align biome classification map\n",
    "# -----------------------------------------\n",
    "biome = rxr.open_rasterio(classification_file).squeeze()\n",
    "biome = biome.rio.reproject_match(dep)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) Load, align, mask, and robustly clip explanatory layers\n",
    "# ----------------------------------------------------------\n",
    "def load_align_clip(fp, ref_da):\n",
    "    x = rxr.open_rasterio(fp).squeeze()\n",
    "    x = x.rio.reproject_match(ref_da)\n",
    "    # Mask to valid dependent pixels\n",
    "    x = x.where(~ref_da.isnull())\n",
    "    # Robust clip to [1st, 99th] percentile on finite values only\n",
    "    vals = x.values\n",
    "    finite = np.isfinite(vals)\n",
    "    if finite.any():\n",
    "        lo = np.nanpercentile(vals[finite], 1)\n",
    "        hi = np.nanpercentile(vals[finite], 99)\n",
    "        # Guard against degenerate lo/hi\n",
    "        if np.isfinite(lo) and np.isfinite(hi) and lo < hi:\n",
    "            x = x.clip(min=lo, max=hi)\n",
    "    return x\n",
    "\n",
    "exps = Parallel(n_jobs=-1)(\n",
    "    delayed(load_align_clip)(fp, dep) for fp in explanatory_files\n",
    ")\n",
    "feature_names = [os.path.splitext(os.path.basename(fp))[0] for fp in explanatory_files]\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Utility: normalized RF feature importances\n",
    "# ------------------------------------------------\n",
    "def rf_relative_importance(dep_da, exp_list, rnd=42):\n",
    "    dep_vals = dep_da.values.flatten()\n",
    "    X = np.stack([e.values.flatten() for e in exp_list], axis=1)\n",
    "\n",
    "    mask = np.isfinite(dep_vals) & np.all(np.isfinite(X), axis=1)\n",
    "    Xm, ym = X[mask], dep_vals[mask]\n",
    "\n",
    "    # Avoid training on too few samples\n",
    "    if ym.size < 100:\n",
    "        return np.full(len(exp_list), np.nan, dtype=float)\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        n_jobs=-1,\n",
    "        random_state=rnd,\n",
    "        # Optional: you may set max_features=\"sqrt\" or similar if desired\n",
    "    )\n",
    "    rf.fit(Xm, ym)\n",
    "    imp = np.asarray(rf.feature_importances_, dtype=float)\n",
    "    s = imp.sum()\n",
    "    return imp / s if s > 0 else np.full_like(imp, np.nan, dtype=float)\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Overall relative importance\n",
    "# -------------------------------\n",
    "overall = rf_relative_importance(dep, exps)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 6) Biome-wise (zone-wise) relative importance\n",
    "# --------------------------------------------\n",
    "result = {\"Feature\": feature_names, \"Overall\": overall}\n",
    "for code, name in biome_map.items():\n",
    "    zone_mask = biome == code\n",
    "    dep_z = dep.where(zone_mask)\n",
    "    exps_z = [e.where(zone_mask) for e in exps]\n",
    "    result[name] = rf_relative_importance(dep_z, exps_z)\n",
    "\n",
    "# ----------------\n",
    "# 7) Save to CSV\n",
    "# ----------------\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# (Optional) sort rows by Overall importance descending for readability\n",
    "try:\n",
    "    df = df.sort_values(by=\"Overall\", ascending=False)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "out_csv = r\"./RF_Importance_Zonewise.csv\"\n",
    "df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Saved overall and biome-wise importances to: {out_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
